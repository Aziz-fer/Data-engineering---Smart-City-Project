## OVERVIEW

## Building an End-to-End Real-Time Data Streaming Pipeline for a Smart City:
This pipeline leverages state-of-the-art tools and technologies to manage every phase of data processing, from ingestion to visualization. IoT devices will serve as data sources, transmitting real-time information. Apache Zookeeper and Apache Kafka will handle distributed coordination and message streaming, ensuring scalability and reliability. Apache Spark will process the data in real-time, offering analytics and transformations at scale.

To manage containerized environments and deployment, Docker will be employed. Python will be the primary programming language for custom scripting and integration. The pipeline will be hosted on AWS Cloud, leveraging services such as AWS Glue for ETL processes, AWS Athena for querying, and AWS IAM for secure access management. The processed data will be stored in AWS Redshift, optimized for analytics. Finally, Power BI will provide an intuitive interface to visualize the insights stored in Redshift, enabling actionable decision-making for the smart city.

## Architecture of The Project

![image](https://github.com/eremah/SmartCity/assets/75796623/71b08b0f-0484-4347-87f8-237224cd01f7)
